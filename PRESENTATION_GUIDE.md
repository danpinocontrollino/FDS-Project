# Presentation Guide - Data Quality Insights

## ğŸ¯ Quick Demo Flow (10 Minutes)

### Part 1: Traditional Demo (5 min)
1. **Show Input Sliders** (sidebar)
   - "17 behavioral features collected over 7 days"
   - Adjust a few sliders to show interactivity

2. **Generate Profile** (click button)
   - "LSTM processes in <100ms"
   - Show 8 predictions with color coding

3. **What-If Simulator**
   - Change sleep from 6h â†’ 8h
   - Show corrected predictions (with evidence-based adjustments)
   - "Notice stress goes down - this is the correction layer"

### Part 2: Data Quality Discovery (5 min)
4. **Scroll to "ğŸ“Š Data Quality Insights"**
   - "This is what we discovered during validation..."

5. **Expand Finding 1** (Data Availability)
   - "Real students gave us 85% behavioral data but only 10% mental health surveys"
   - Show detailed breakdown

6. **Expand Finding 2** (Correlations)
   - "Synthetic data: 7Ã— weaker than clinical literature"
   - Point to evidence-based corrections explanation

7. **Read Key Takeaway Box**
   - "This validates the need for our approach"
   - "Automated prediction when surveys aren't filled"

---

## ğŸ’¡ Key Statistics to Quote

### The Synthetic Data Problem
- **Sleep â†’ Stress correlation:** Expected r=-0.40, Got r=-0.07 (7Ã— too weak)
- **Exercise â†’ Mood correlation:** Expected r=+0.35, Got r=+0.09 (3Ã— too weak)
- **1.5M training records** but unrealistic relationships

### The Real-World Discovery
- **StudentLife dataset:** 49 students, 10 weeks, real sensors
- **Behavioral coverage:** 40-85 days per student (excellent)
- **Mental health surveys:** 4-47 responses over 10 weeks (sparse)
- **Why:** Students don't fill surveys daily - this is realistic

### The Evidence-Based Solution
- **What-If simulator:** Overrides model when predictions contradict research
- **6 correction rules:** Sleep, exercise, social, work, caffeine, outdoor time
- **Example:** Sleep Â±1h â†’ Stress/Anxiety Â±0.3-0.4 points (from literature)

---

## ğŸ¤ Script Templates

### Opening (30 sec)
> "We built a comprehensive mental health prediction system using deep learning. During development, we trained on 1.5 million synthetic records and achieved 98.5% accuracy. But when we validated with real student behavioral data, we discovered something important..."

### Discovery (1 min)
> "The StudentLife dataset captured 49 students over 10 weeks with real smartphone sensors. We successfully extracted sleep, exercise, screen time, and social interactions with excellent coverage - 40 to 85 days per student. But mental health self-reports? Only 4 to 47 surveys over 10 weeks. Students don't fill out mental health forms daily - this is the real-world constraint."

### The Problem (1 min)
> "We also found our synthetic training data had unrealistically weak correlations. The literature shows sleep-stress correlation should be around -0.4. Our training data? Only -0.07 - seven times weaker. This explained why our initial What-If simulator showed inverse relationships."

### The Solution (1 min)
> "So we implemented evidence-based corrections. When the model's predictions contradict clinical research, we override them with literature-based adjustments. For example, if you increase sleep by one hour, we adjust stress down by 0.3 to 0.4 points regardless of what the model says - because that's what the research shows."

### The Opportunity (30 sec)
> "This isn't a limitation - it validates the need for our approach. Real-world deployment requires predicting mental health from behavioral sensors when daily surveys aren't realistic. That's exactly what our system is designed to do."

---

## ğŸ–¼ï¸ Chart Usage Guide

### comparison_data_availability.png
**When to use:** Explaining the sparse survey problem  
**Key point:** "100% synthetic coverage vs 10-20% real coverage"  
**Emphasize:** Both are challenges, different trade-offs

### comparison_feature_variance.png
**When to use:** Showing what worked vs what didn't  
**Key point:** "Behavioral features excellent, mental health constant"  
**Emphasize:** Red highlight shows the problem zones

### comparison_correlations.png
**When to use:** Explaining the 7Ã— weakness problem  
**Key point:** "Expected -0.40, got -0.07, StudentLife N/A"  
**Emphasize:** Horizontal bars show magnitude clearly

### comparison_summary_table.png
**When to use:** Q&A or backup slide  
**Key point:** Comprehensive side-by-side comparison  
**Emphasize:** Trade-offs table is professional

---

## â“ Anticipated Questions & Answers

### Q: "Why use synthetic data if correlations are weak?"
**A:** "We needed scale for initial development - 1.5M records trains robust models. Real data validated our features work but confirmed the mental health data gap. In production, we'd use transfer learning: pre-train on synthetic, fine-tune on real behavioral signals."

### Q: "Can you retrain with better data?"
**A:** "The StudentLife data shows the problem isn't finding 'better' data - it's that daily mental health self-reports don't exist in real settings. Our architecture is designed for exactly this: predict from sensors when surveys aren't filled. That's the value proposition."

### Q: "How do evidence-based corrections work?"
**A:** "Six behavioral-outcome relationships from clinical literature. When model predictions deviate more than our threshold (Â±0.1), we interpolate toward literature values. It's a hybrid: data-driven baseline, knowledge-based bounds."

### Q: "What about other validation datasets?"
**A:** "StudentLife is one of the largest open behavioral sensing studies. Other options like TILES or SNAPSHOT have similar sparse survey issues - this appears to be a fundamental real-world constraint, not a dataset artifact."

### Q: "Could you collect your own data?"
**A:** "Yes, but you'd face the same challenge: convincing people to fill daily surveys for weeks. Our system's advantage is predicting when they don't. For immediate validation, we relied on behavioral sensor comparison, which showed 85-90% match with expected patterns."

---

## ğŸ¯ Closing Statements

### Strong Close (Research Angle)
> "We set out to build a mental health prediction system and discovered why this problem is harder than academic datasets suggest. Our validation revealed both the limitations of synthetic training data AND the real-world challenge of sparse self-reports. Rather than a setback, this finding validates the need for our sensor-based approach. In deployment, we can collect behavioral data passively and predict mental health when users don't fill surveys - exactly the problem we identified."

### Confident Close (System Focus)
> "Our system demonstrates 98.5% accuracy on job satisfaction, 97% on anxiety and depression. We've implemented 332 evidence-based interventions, integrated clinical validation frameworks, and built real-time prediction with sub-100ms latency. The data quality insights we discovered strengthen rather than weaken our approach - they show we understand both the technical challenges and real-world deployment constraints."

### Future Work Close (Research Path)
> "Next steps: collect longitudinal data with sparse surveys, validate prediction drift over time, implement transfer learning from synthetic to real behavioral signals, and deploy pilot study measuring prediction accuracy against weekly rather than daily mental health reports. The system is ready - we've identified what deployment will require."

---

## â° Time Management

**10-Minute Version:**
- Demo: 5 min
- Data Quality: 4 min
- Q&A: 1 min

**15-Minute Version:**
- Intro: 1 min
- Demo: 7 min
- Data Quality: 5 min
- Q&A: 2 min

**20-Minute Version:**
- Intro: 2 min
- Architecture: 3 min
- Demo: 7 min
- Data Quality: 5 min
- Q&A: 3 min

---

## ğŸš€ Pre-Presentation Checklist

### 1 Week Before
- [ ] Practice demo flow 3+ times
- [ ] Test all expandable sections
- [ ] Ensure charts display correctly
- [ ] Backup: Record demo video (in case live fails)
- [ ] Backup: Export charts to USB drive

### 1 Day Before
- [ ] Test demo on presentation laptop
- [ ] Verify network/projector connectivity
- [ ] Print 1 copy of script with key stats
- [ ] Charge laptop fully
- [ ] Set browser to demo URL in bookmarks

### Day Of
- [ ] Arrive 30 min early
- [ ] Test tech setup
- [ ] Open demo in browser tab
- [ ] Have backup slides ready
- [ ] Water bottle nearby
- [ ] Deep breath - you've got this!

---

## ğŸ’ª Confidence Boosters

1. **You made a research discovery** - not many student projects do
2. **Your system works** - 98.5% accuracy on some targets
3. **Your approach is valid** - sensor-based prediction is the solution
4. **Your insights are valuable** - published papers on this exact challenge
5. **You're prepared** - 9 days, clear plan, working demo

**Remember:** The best presentations don't hide problems - they show how you discovered, understood, and addressed them. That's exactly what you've done here.

Good luck! ğŸ‰
