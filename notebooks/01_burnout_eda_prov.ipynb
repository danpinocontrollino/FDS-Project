{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a15e264",
   "metadata": {},
   "source": [
    "# ðŸ“Š Provisional EDA - Burnout Labels Creation\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook is a preliminary/provisional version of the EDA focused on **target variable creation** (burnout_score and burnout_level).\n",
    "\n",
    "### Workflow\n",
    "1. Load the 4 raw datasets from Kaggle\n",
    "2. Create composite burnout score (z-score)\n",
    "3. Discretize into 3 classes using percentiles\n",
    "4. Merge with daily data to propagate labels\n",
    "\n",
    "> **Note**: The final and more complete version is in `01_eda.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef21ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily logs: (731000, 26)\n",
      "Daily all: (731000, 53)\n",
      "Interventions: (332, 6)\n",
      "Weekly summaries: (105000, 10)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING\n",
    "# =============================================================================\n",
    "# Import necessary libraries and load all datasets\n",
    "# from the data/raw/ folder (downloaded from Kaggle)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Load all 4 dataset files\n",
    "daily_logs = pd.read_csv(\"../data/raw/daily_logs.csv\")      # Daily metrics\n",
    "daily_all = pd.read_csv(\"../data/raw/daily_all.csv\")        # Expanded version\n",
    "interventions = pd.read_csv(\"../data/raw/interventions.csv\") # Wellness interventions\n",
    "weekly = pd.read_csv(\"../data/raw/weekly_summaries.csv\")     # Weekly summaries\n",
    "\n",
    "# Print dimensions for verification\n",
    "print(\"Daily logs:\", daily_logs.shape)      # ~365k rows (1000 users Ã— 365 days)\n",
    "print(\"Daily all:\", daily_all.shape)\n",
    "print(\"Interventions:\", interventions.shape)\n",
    "print(\"Weekly summaries:\", weekly.shape)    # ~52k rows (1000 users Ã— 52 weeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb7cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BURNOUT SCORE CREATION\n",
    "# =============================================================================\n",
    "# Burnout is not directly observable in the dataset.\n",
    "# We derive it by combining correlated psychometric indicators.\n",
    "#\n",
    "# FORMULA:\n",
    "# burnout = (z_stress + z_anxiety + z_depression + z_sleep_debt - z_job_satisfaction) / 5\n",
    "#\n",
    "# Where z_* indicates the standardized value (z-score) of each variable.\n",
    "# Standardization makes the scales comparable.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select columns that contribute to burnout\n",
    "# These are available in the weekly_summaries dataset\n",
    "burnout_features = weekly[[\n",
    "    \"perceived_stress_scale\",  # PSS-10: Perceived Stress Scale (0-40)\n",
    "    \"anxiety_score\",           # GAD-7: Generalized Anxiety Disorder scale\n",
    "    \"depression_score\",        # PHQ-9: Patient Health Questionnaire for depression\n",
    "    \"sleep_debt_hours\",        # Hours of sleep lost relative to ideal needs\n",
    "    \"job_satisfaction\",        # Job satisfaction scale (1-10)\n",
    "]]\n",
    "\n",
    "# Z-score standardization\n",
    "# Transforms each column to: (x - mean) / standard_deviation\n",
    "# Result: mean = 0, std = 1 for each column\n",
    "scaler = StandardScaler()\n",
    "burnout_z = scaler.fit_transform(burnout_features)\n",
    "\n",
    "burnout_z = pd.DataFrame(\n",
    "    burnout_z,\n",
    "    columns=burnout_features.columns,\n",
    "    index=weekly.index\n",
    ")\n",
    "\n",
    "# Calculate composite burnout score\n",
    "# NOTE: job_satisfaction has NEGATIVE coefficient because it's a protective factor\n",
    "# (high satisfaction = low burnout)\n",
    "weekly[\"burnout_score\"] = (\n",
    "    burnout_z[\"perceived_stress_scale\"]\n",
    "    + burnout_z[\"anxiety_score\"]\n",
    "    + burnout_z[\"depression_score\"]\n",
    "    + burnout_z[\"sleep_debt_hours\"]\n",
    "    - burnout_z[\"job_satisfaction\"]  # Subtracted!\n",
    ") / 5.0  # Average of 5 contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38268a0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.050000e+05\n",
       "mean    -1.808162e-16\n",
       "std      6.748538e-01\n",
       "min     -2.011962e+00\n",
       "25%     -4.795661e-01\n",
       "50%     -1.075208e-01\n",
       "75%      3.998777e-01\n",
       "max      4.497371e+00\n",
       "Name: burnout_score, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BURNOUT SCORE DESCRIPTIVE STATISTICS\n",
    "# =============================================================================\n",
    "# Verify that the burnout score has a reasonable distribution\n",
    "\n",
    "weekly[\"burnout_score\"].describe()\n",
    "\n",
    "# Expected output:\n",
    "# - mean â‰ˆ 0 (because we use z-scores)\n",
    "# - std â‰ˆ 0.4-0.6 (combination of 5 standardized variables)\n",
    "# - min/max reasonable (no extreme outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5603eb29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "burnout_level\n",
       "2    35700\n",
       "1    34658\n",
       "0    34642\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DISCRETIZATION INTO 3 CLASSES\n",
    "# =============================================================================\n",
    "# For classification, we convert continuous burnout into 3 levels:\n",
    "# - 0 = Low (low burnout)\n",
    "# - 1 = Medium (medium)\n",
    "# - 2 = High (high burnout)\n",
    "#\n",
    "# We use 33rd and 66th percentiles to ensure balanced classes.\n",
    "\n",
    "low_thr = weekly[\"burnout_score\"].quantile(0.33)   # Threshold between low and medium\n",
    "high_thr = weekly[\"burnout_score\"].quantile(0.66)  # Threshold between medium and high\n",
    "\n",
    "def burnout_class(score):\n",
    "    \"\"\"Convert continuous burnout score to discrete class.\"\"\"\n",
    "    if score < low_thr:\n",
    "        return 0  # Low burnout\n",
    "    elif score < high_thr:\n",
    "        return 1  # Medium burnout\n",
    "    else:\n",
    "        return 2  # High burnout\n",
    "\n",
    "weekly[\"burnout_level\"] = weekly[\"burnout_score\"].apply(burnout_class)\n",
    "\n",
    "# Verify class balance\n",
    "# We should see approximately 33% for each class\n",
    "weekly[\"burnout_level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c807cdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MERGE WITH DAILY DATA\n",
    "# =============================================================================\n",
    "# Burnout is calculated at weekly level, but we want to use daily\n",
    "# features for training. We merge based on (user_id, week) to\n",
    "# propagate burnout_level to each day.\n",
    "\n",
    "# Convert dates to datetime\n",
    "daily_logs[\"date\"] = pd.to_datetime(daily_logs[\"date\"])\n",
    "weekly[\"week_start\"] = pd.to_datetime(weekly[\"week_start\"])\n",
    "\n",
    "# Extract ISO week number (1-52)\n",
    "daily_logs[\"week\"] = daily_logs[\"date\"].dt.isocalendar().week\n",
    "weekly[\"week\"] = weekly[\"week_start\"].dt.isocalendar().week\n",
    "\n",
    "# Left join: keep all daily records\n",
    "# and add burnout_score/level from the corresponding week\n",
    "merged = pd.merge(\n",
    "    daily_logs,\n",
    "    weekly[[\"user_id\", \"week\", \"burnout_score\", \"burnout_level\"]],\n",
    "    on=[\"user_id\", \"week\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(f\"Merged dataset shape: {merged.shape}\")\n",
    "print(f\"Missing burnout values: {merged['burnout_level'].isna().sum()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
