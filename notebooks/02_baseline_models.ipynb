{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a0af4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1023727272.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m\"def evaluate_classifier(model, X_tr, X_te, y_tr, y_te):\",\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "    \"def evaluate_classifier(model, X_tr, X_te, y_tr, y_te):\",\n",
    "    \"    model.fit(X_tr, y_tr)\",\n",
    "    \"    preds = model.predict(X_te)\",\n",
    "    \"    if hasattr(model, 'predict_proba'):\",\n",
    "    \"        probs = model.predict_proba(X_te)\",\n",
    "    \"        roc = roc_auc_score(y_te, probs, multi_class='ovr')\",\n",
    "    \"    else:\",\n",
    "    \"        probs = None\",\n",
    "    \"        roc = np.nan\",\n",
    "    \"    metrics = {\",\n",
    "    \"        'accuracy': accuracy_score(y_te, preds)\",\n",
    "    \"        , 'f1_macro': f1_score(y_te, preds, average='macro')\",\n",
    "    \"        , 'roc_auc_ovr': roc\",\n",
    "    \"    }\",\n",
    "    \"    return metrics, preds, probs\"\n",
    "{\n",
    "    \"cells\": [\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"id\": \"#VSC-0c71c676\",\n",
    "            \"metadata\": {\n",
    "                \"language\": \"python\"\n",
    "            },\n",
    "            \"source\": [\n",
    "                \"from pathlib import Path\",\n",
    "                \"import json\",\n",
    "                \"import numpy as np\",\n",
    "                \"import pandas as pd\",\n",
    "                \"import matplotlib.pyplot as plt\",\n",
    "                \"import seaborn as sns\",\n",
    "                \"from sklearn.model_selection import train_test_split\",\n",
    "                \"from sklearn.preprocessing import StandardScaler\",\n",
    "                \"from sklearn.linear_model import LogisticRegression, LinearRegression\",\n",
    "                \"from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\",\n",
    "                \"from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, classification_report, mean_absolute_error, mean_squared_error\",\n",
    "                \"import joblib\",\n",
    "                \"\",\n",
    "                \"sns.set_theme(style='whitegrid', context='talk')\",\n",
    "                \"DATA_DIR = Path('../data/processed')\",\n",
    "                \"MODEL_DIR = Path('../models/saved')\",\n",
    "                \"MODEL_DIR.mkdir(parents=True, exist_ok=True)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"id\": \"#VSC-a146c755\",\n",
    "            \"metadata\": {\n",
    "                \"language\": \"python\"\n",
    "            },\n",
    "            \"source\": [\n",
    "                \"tabular_path = DATA_DIR / 'tabular_ml_ready.parquet'\",\n",
    "                \"if not tabular_path.exists():\",\n",
    "                \"    raise FileNotFoundError('Run scripts/preprocess.py to create tabular_ml_ready.parquet')\",\n",
    "                \"df = pd.read_parquet(tabular_path)\",\n",
    "                \"feature_cols = [c for c in df.columns if c not in ['burnout_level', 'burnout_score']]\",\n",
    "                \"X = df[feature_cols]\",\n",
    "                \"y_class = df['burnout_level']\",\n",
    "                \"y_reg = df['burnout_score']\",\n",
    "                \"X_train, X_test, y_train, y_test = train_test_split(X, y_class, stratify=y_class, test_size=0.2, random_state=42)\",\n",
    "                \"_, _, y_train_reg, y_test_reg = train_test_split(X, y_reg, stratify=None, test_size=0.2, random_state=42)\",\n",
    "                \"X_train.shape, X_test.shape\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"id\": \"#VSC-e4b09336\",\n",
    "            \"metadata\": {\n",
    "                \"language\": \"python\"\n",
    "            },\n",
    "            \"source\": [\n",
    "                \"def evaluate_classifier(model, X_tr, X_te, y_tr, y_te):\",\n",
    "                \"    model.fit(X_tr, y_tr)\",\n",
    "                \"    preds = model.predict(X_te)\",\n",
    "                \"    return metrics, preds, probs\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"id\": \"#VSC-e26eb89b\",\n",
    "            \"metadata\": {\n",
    "                \"language\": \"python\"\n",
    "            },\n",
    "            \"source\": [\n",
    "                \"results_clf = {}\",\n",
    "                \"log_reg = LogisticRegression(max_iter=2000, multi_class='multinomial')\",\n",
    "                \"metrics, preds = evaluate_classifier(log_reg, X_train, X_test, y_train, y_test)\",\n",
    "                \"results_clf['logistic_regression'] = metrics\",\n",
    "                \"joblib.dump(log_reg, MODEL_DIR / 'log_reg.pkl')\",\n",
    "                \"\",\n",
    "                \"rf_clf = RandomForestClassifier(n_estimators=400, random_state=42, class_weight='balanced_subsample')\",\n",
    "                \"metrics, rf_preds = evaluate_classifier(rf_clf, X_train, X_test, y_train, y_test)\",\n",
    "                \"results_clf['random_forest'] = metrics\",\n",
    "                \"joblib.dump(rf_clf, MODEL_DIR / 'rf_classifier.pkl')\",\n",
    "                \"\",\n",
    "                \"gb_clf = GradientBoostingClassifier(random_state=42)\",\n",
    "                \"metrics, gb_preds = evaluate_classifier(gb_clf, X_train, X_test, y_train, y_test)\",\n",
    "                \"results_clf['gradient_boosting'] = metrics\",\n",
    "                \"joblib.dump(gb_clf, MODEL_DIR / 'gb_classifier.pkl')\",\n",
    "                \"results_clf\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"id\": \"#VSC-afa9dfd5\",\n",
    "            \"metadata\": {\n",
    "                \"language\": \"python\"\n",
    "            },\n",
    "            \"source\": [\n",
    "                \"def plot_conf_matrix(y_true, y_pred, title):\",\n",
    "                \"    cm = confusion_matrix(y_true, y_pred)\",\n",
    "                \"    plt.figure(figsize=(6, 5))\",\n",
    "                \"    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d')\",\n",
    "                \"    plt.title(title)\",\n",
    "                \"    plt.xlabel('Predicted')\",\n",
    "                \"    plt.ylabel('True')\",\n",
    "                \"    plt.tight_layout()\",\n",
    "                \"\",\n",
    "                \"plot_conf_matrix(y_test, rf_preds, 'Random Forest Confusion Matrix')\",\n",
    "                \"plot_conf_matrix(y_test, gb_preds, 'Gradient Boosting Confusion Matrix')\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"id\": \"#VSC-90fa9194\",\n",
    "            \"metadata\": {\n",
    "                \"language\": \"python\"\n",
    "            },\n",
    "            \"source\": [\n",
    "                \"rf_importances = pd.Series(rf_clf.feature_importances_, index=feature_cols)\",\n",
    "                \"top_feats = rf_importances.sort_values(ascending=False).head(15)\",\n",
    "                \"plt.figure(figsize=(8, 6))\",\n",
    "                \"sns.barplot(x=top_feats.values, y=top_feats.index, palette='viridis')\",\n",
    "                \"plt.title('Random Forest Feature Importance (Top 15)')\",\n",
    "                \"plt.tight_layout()\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"id\": \"#VSC-b54fc877\",\n",
    "            \"metadata\": {\n",
    "                \"language\": \"python\"\n",
    "            },\n",
    "            \"source\": [\n",
    "                \"def evaluate_regressor(model, X_tr, X_te, y_tr, y_te):\",\n",
    "                \"    model.fit(X_tr, y_tr)\",\n",
    "                \"    preds = model.predict(X_te)\",\n",
    "                \"    return {\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"id\": \"#VSC-7c7b9531\",\n",
    "            \"metadata\": {\n",
    "                \"language\": \"python\"\n",
    "            },\n",
    "            \"source\": [\n",
    "                \"results_reg = {}\",\n",
    "                \"lin_reg = LinearRegression()\",\n",
    "                \"results_reg['linear_regression'] = evaluate_regressor(lin_reg, X_train, X_test, y_train_reg, y_test_reg)\",\n",
    "                \"joblib.dump(lin_reg, MODEL_DIR / 'linear_reg.pkl')\",\n",
    "                \"\",\n",
    "                \"rf_reg = RandomForestRegressor(n_estimators=400, random_state=42)\",\n",
    "                \"results_reg['random_forest_regressor'] = evaluate_regressor(rf_reg, X_train, X_test, y_train_reg, y_test_reg)\",\n",
    "                \"joblib.dump(rf_reg, MODEL_DIR / 'rf_regressor.pkl')\",\n",
    "                \"results_reg\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"id\": \"#VSC-1e657785\",\n",
    "            \"metadata\": {\n",
    "                \"language\": \"python\"\n",
    "            },\n",
    "            \"source\": [\n",
    "                \"display(pd.DataFrame(results_clf).T)\",\n",
    "                \"display(pd.DataFrame(results_reg).T)\"\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"id\": \"#VSC-dca1e2bd\",\n",
    "            \"metadata\": {\n",
    "                \"language\": \"markdown\"\n",
    "            },\n",
    "            \"source\": [\n",
    "                \"## Notes\",\n",
    "                \"- Re-run after feature tweaks to compare models.\",\n",
    "                \"- Saved estimators live in `../models/saved/` for downstream ensembling or deployment.\"\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b93b643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, classification_report, mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "\n",
    "sns.set_theme(style='whitegrid', context='talk')\n",
    "DATA_DIR = Path('../data/processed')\n",
    "MODEL_DIR = Path('../models/saved')\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605ef4c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tabular_path.exists():\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mRun scripts/preprocess.py to create tabular_ml_ready.parquet\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtabular_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m feature_cols = [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m df.columns \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mburnout_level\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mburnout_score\u001b[39m\u001b[33m'\u001b[39m]]\n\u001b[32m      6\u001b[39m X = df[feature_cols]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parquet.py:653\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    500\u001b[39m \u001b[38;5;129m@doc\u001b[39m(storage_options=_shared_docs[\u001b[33m\"\u001b[39m\u001b[33mstorage_options\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    501\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_parquet\u001b[39m(\n\u001b[32m    502\u001b[39m     path: FilePath | ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    510\u001b[39m     **kwargs,\n\u001b[32m    511\u001b[39m ) -> DataFrame:\n\u001b[32m    512\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    513\u001b[39m \u001b[33;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[32m    514\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    650\u001b[39m \u001b[33;03m    1    4    9\u001b[39;00m\n\u001b[32m    651\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     impl = \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m use_nullable_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib.no_default:\n\u001b[32m    656\u001b[39m         msg = (\n\u001b[32m    657\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe argument \u001b[39m\u001b[33m'\u001b[39m\u001b[33muse_nullable_dtypes\u001b[39m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will be removed \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    658\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33min a future version.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    659\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/io/parquet.py:68\u001b[39m, in \u001b[36mget_engine\u001b[39m\u001b[34m(engine)\u001b[39m\n\u001b[32m     65\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     66\u001b[39m             error_msgs += \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m - \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(err)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     69\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnable to find a usable engine; \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtried using: \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mfastparquet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     71\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA suitable version of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msupport.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mTrying to import the above resulted in these errors:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[31mImportError\u001b[39m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "tabular_path = DATA_DIR / 'tabular_ml_ready.parquet'\n",
    "if not tabular_path.exists():\n",
    "    raise FileNotFoundError('Run scripts/preprocess.py to create tabular_ml_ready.parquet')\n",
    "df = pd.read_parquet(tabular_path)\n",
    "feature_cols = [c for c in df.columns if c not in ['burnout_level', 'burnout_score']]\n",
    "X = df[feature_cols]\n",
    "y_class = df['burnout_level']\n",
    "y_reg = df['burnout_score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_class, stratify=y_class, test_size=0.2, random_state=42)\n",
    "_, _, y_train_reg, y_test_reg = train_test_split(X, y_reg, stratify=None, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb1ab6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(model, X_tr, X_te, y_tr, y_te):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    preds = model.predict(X_te)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        probs = model.predict_proba(X_te)\n",
    "        roc = roc_auc_score(y_te, probs, multi_class=\"ovr\")\n",
    "    else:\n",
    "        probs = None\n",
    "        roc = np.nan\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(y_te, preds),\n",
    "        \"f1_macro\": f1_score(y_te, preds, average=\"macro\"),\n",
    "        \"roc_auc_ovr\": roc,\n",
    "    }\n",
    "    return metrics, preds, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4930095",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_clf = {}\n",
    "log_reg = LogisticRegression(max_iter=2000, multi_class='multinomial')\n",
    "metrics, preds, log_probs = evaluate_classifier(log_reg, X_train, X_test, y_train, y_test)\n",
    "results_clf['logistic_regression'] = metrics\n",
    "joblib.dump(log_reg, MODEL_DIR / 'log_reg.pkl')\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=400, random_state=42, class_weight='balanced_subsample')\n",
    "metrics, rf_preds, rf_probs = evaluate_classifier(rf_clf, X_train, X_test, y_train, y_test)\n",
    "results_clf['random_forest'] = metrics\n",
    "joblib.dump(rf_clf, MODEL_DIR / 'rf_classifier.pkl')\n",
    "\n",
    "gb_clf = GradientBoostingClassifier(random_state=42)\n",
    "metrics, gb_preds, gb_probs = evaluate_classifier(gb_clf, X_train, X_test, y_train, y_test)\n",
    "results_clf['gradient_boosting'] = metrics\n",
    "joblib.dump(gb_clf, MODEL_DIR / 'gb_classifier.pkl')\n",
    "results_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_matrix(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, cmap='Blues', fmt='d')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_conf_matrix(y_test, rf_preds, 'Random Forest Confusion Matrix')\n",
    "plot_conf_matrix(y_test, gb_preds, 'Gradient Boosting Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0824fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "classes = sorted(y_test.unique())\n",
    "for idx, label in enumerate(classes):\n",
    "    fpr, tpr, _ = roc_curve((y_test == label).astype(int), rf_probs[:, idx])\n",
    "    plt.plot(fpr, tpr, label=f\"Class {label}\")\n",
    "plt.plot([0, 1], [0, 1], \"--\", color=\"gray\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Random Forest ROC (One-vs-Rest)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81412492",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_importances = pd.Series(rf_clf.feature_importances_, index=feature_cols)\n",
    "top_feats = rf_importances.sort_values(ascending=False).head(15)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=top_feats.values, y=top_feats.index, palette='viridis')\n",
    "plt.title('Random Forest Feature Importance (Top 15)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e5bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regressor(model, X_tr, X_te, y_tr, y_te):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    preds = model.predict(X_te)\n",
    "    return {\n",
    "        \"mae\": mean_absolute_error(y_te, preds),\n",
    "        \"mse\": mean_squared_error(y_te, preds),\n",
    "        \"rmse\": mean_squared_error(y_te, preds, squared=False),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29b4f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_reg = {}\n",
    "lin_reg = LinearRegression()\n",
    "results_reg['linear_regression'] = evaluate_regressor(lin_reg, X_train, X_test, y_train_reg, y_test_reg)\n",
    "joblib.dump(lin_reg, MODEL_DIR / 'linear_reg.pkl')\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=400, random_state=42)\n",
    "results_reg['random_forest_regressor'] = evaluate_regressor(rf_reg, X_train, X_test, y_train_reg, y_test_reg)\n",
    "joblib.dump(rf_reg, MODEL_DIR / 'rf_regressor.pkl')\n",
    "results_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689f3fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.DataFrame(results_clf).T)\n",
    "display(pd.DataFrame(results_reg).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f56318",
   "metadata": {},
   "source": [
    "## Notes\n",
    "- Re-run after feature tweaks to compare models.\n",
    "- Saved estimators live in `../models/saved/` for downstream ensembling or deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
