{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68fec76",
   "metadata": {},
   "source": [
    "# üîÆ What-If Engine - Analisi Scenari\n",
    "\n",
    "## Obiettivo\n",
    "\n",
    "Questo notebook implementa un **\"What-If Engine\"** per esplorare come modifiche comportamentali influenzano il rischio di burnout.\n",
    "\n",
    "### Caso d'Uso\n",
    "Un dipendente con alto rischio di burnout vuole sapere:\n",
    "> \"Se dormo 1 ora in pi√π e riduco 2 ore di screen time, il mio rischio diminuisce?\"\n",
    "\n",
    "### Come Funziona\n",
    "1. Prendiamo un esempio dal dataset (es. un caso di alto burnout)\n",
    "2. Applichiamo modifiche (\"deltas\") a specifiche features\n",
    "3. Confrontiamo le probabilit√† predette prima/dopo\n",
    "\n",
    "### Applicazioni Pratiche\n",
    "- **HR Analytics**: identificare interventi personalizzati per dipendenti a rischio\n",
    "- **Self-monitoring**: app di wellness che suggerisce cambiamenti comportamentali\n",
    "- **Policy making**: valutare impatto di politiche aziendali (es. riduzione orario)\n",
    "\n",
    "### Limitazioni\n",
    "- Il modello predice **correlazioni**, non **causalit√†**\n",
    "- Gli interventi reali potrebbero avere effetti diversi\n",
    "- Dataset sintetico: validare su dati reali prima del deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0f563",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/processed/X_train.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Carica i dati pre-processati come fai in 02/03 (adatta se li salvi su pickle)\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m X_train = \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/processed/X_train.joblib\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m X_test = load(\u001b[33m\"\u001b[39m\u001b[33mdata/processed/X_test.joblib\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m y_train = load(\u001b[33m\"\u001b[39m\u001b[33mdata/processed/y_train.joblib\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/joblib/numpy_pickle.py:735\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    733\u001b[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[32m    737\u001b[39m             fobj,\n\u001b[32m    738\u001b[39m             validated_mmap_mode,\n\u001b[32m    739\u001b[39m         ):\n\u001b[32m    740\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    741\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    742\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    743\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/processed/X_train.joblib'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SETUP E CARICAMENTO MODELLO\n",
    "# =============================================================================\n",
    "# Carichiamo il modello MLP allenato per fare predizioni what-if\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('../data/processed')\n",
    "MODEL_DIR = Path('../models/saved')\n",
    "\n",
    "# =============================================================================\n",
    "# CARICAMENTO DATI\n",
    "# =============================================================================\n",
    "# Usiamo lo stesso dataset del training per avere features consistenti\n",
    "\n",
    "df = pd.read_parquet(DATA_DIR / 'tabular_ml_ready.parquet')\n",
    "feature_cols = [c for c in df.columns if c not in {'burnout_level', 'burnout_score'}]\n",
    "X = df[feature_cols].values.astype(np.float32)\n",
    "y = df['burnout_level'].values.astype(np.int64)\n",
    "\n",
    "# Split identico al training (stesso random_state!)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Convertiamo in DataFrame per avere nomi colonne\n",
    "X_train = pd.DataFrame(X_train, columns=feature_cols)\n",
    "X_test = pd.DataFrame(X_test, columns=feature_cols)\n",
    "\n",
    "# =============================================================================\n",
    "# CARICAMENTO MODELLO MLP\n",
    "# =============================================================================\n",
    "# Definiamo la stessa architettura usata nel training\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Stessa architettura di 03_deep_learning_mlp.ipynb\"\"\"\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Carica il modello salvato\n",
    "model_path = MODEL_DIR / 'mlp_classifier.pt'\n",
    "if model_path.exists():\n",
    "    checkpoint = torch.load(model_path, map_location=DEVICE, weights_only=False)\n",
    "    mlp = MLP(len(feature_cols), 3).to(DEVICE)\n",
    "    mlp.load_state_dict(checkpoint['model_state'])\n",
    "    mlp.eval()  # Modalit√† inferenza\n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "else:\n",
    "    print(f\"‚ùå Model not found at {model_path}. Run train_mlp.py first.\")\n",
    "\n",
    "# Carica scaler (opzionale, per de-normalizzare le features)\n",
    "scaler_path = DATA_DIR / 'feature_scaler.joblib'\n",
    "scaler = joblib.load(scaler_path) if scaler_path.exists() else None\n",
    "feature_names = feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef25f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# WHAT-IF FUNCTION\n",
    "# =============================================================================\n",
    "# Funzione principale per analisi scenari\n",
    "\n",
    "def what_if_scenario(model, x_row: pd.Series, deltas: dict, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Analizza come le modifiche alle features cambiano le predizioni.\n",
    "    \n",
    "    Args:\n",
    "        model: Modello PyTorch allenato\n",
    "        x_row: Una riga di features (pd.Series con nomi colonne)\n",
    "        deltas: Dict {nome_feature: variazione}\n",
    "                Es: {\"sleep_hours_mean\": +1.0} = +1 ora di sonno\n",
    "        device: Torch device\n",
    "    \n",
    "    Returns:\n",
    "        dict con:\n",
    "        - x_base: features originali\n",
    "        - x_new: features modificate\n",
    "        - base_proba: probabilit√† per classe (originali)\n",
    "        - new_proba: probabilit√† per classe (dopo modifica)\n",
    "        - proba_change: differenza new - base\n",
    "    \"\"\"\n",
    "    x_base = x_row.copy()\n",
    "    x_new = x_row.copy()\n",
    "    \n",
    "    # Applica le modifiche\n",
    "    for feat, delta in deltas.items():\n",
    "        if feat in x_new.index:\n",
    "            x_new[feat] = x_new[feat] + delta\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: feature '{feat}' not found in data\")\n",
    "\n",
    "    # Predizioni\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Converti in tensori\n",
    "        x_base_tensor = torch.from_numpy(\n",
    "            x_base.values.astype(np.float32)\n",
    "        ).unsqueeze(0).to(device)\n",
    "        x_new_tensor = torch.from_numpy(\n",
    "            x_new.values.astype(np.float32)\n",
    "        ).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        base_logits = model(x_base_tensor)\n",
    "        new_logits = model(x_new_tensor)\n",
    "        \n",
    "        # Converti logits in probabilit√†\n",
    "        base_proba = torch.softmax(base_logits, dim=1).cpu().numpy()[0]\n",
    "        new_proba = torch.softmax(new_logits, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    return {\n",
    "        \"x_base\": x_base,\n",
    "        \"x_new\": x_new,\n",
    "        \"base_proba\": base_proba,           # [P(low), P(medium), P(high)]\n",
    "        \"new_proba\": new_proba,\n",
    "        \"proba_change\": new_proba - base_proba,  # Differenza\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4b76c",
   "metadata": {},
   "source": [
    "## üß™ Esempio: Scenario di Intervento\n",
    "\n",
    "Prendiamo un caso di **alto burnout** dal test set e simuliamo un intervento:\n",
    "- +1 ora di sonno (`sleep_hours_mean`)\n",
    "- -2 ore di screen time (`screen_time_hours_mean`)\n",
    "- -1 ora di lavoro (`work_hours_mean`)\n",
    "\n",
    "Questo simula una settimana con migliore work-life balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f2102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ESECUZIONE WHAT-IF ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "# Troviamo un caso di alto burnout (classe 2) per l'analisi\n",
    "mask_high = (y_test == 2)\n",
    "high_indices = np.where(mask_high)[0]\n",
    "\n",
    "if len(high_indices) > 0:\n",
    "    # Prendiamo il primo caso di alto burnout\n",
    "    idx = high_indices[0]\n",
    "    x_example = X_test.iloc[idx]\n",
    "    \n",
    "    # Definiamo lo scenario: miglioriamo sonno, riduciamo screen time e lavoro\n",
    "    deltas = {\n",
    "        \"sleep_hours_mean\": +1.0,       # +1 ora di sonno medio\n",
    "        \"screen_time_hours_mean\": -2.0,  # -2 ore di screen time medio\n",
    "        \"work_hours_mean\": -1.0,         # -1 ora di lavoro medio\n",
    "    }\n",
    "    \n",
    "    # Eseguiamo l'analisi\n",
    "    result = what_if_scenario(mlp, x_example, deltas)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # VISUALIZZAZIONE RISULTATI\n",
    "    # =============================================================================\n",
    "    print(\"=\" * 50)\n",
    "    print(\"üîÆ WHAT-IF ANALYSIS RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\nüìä Scenario:\")\n",
    "    for feat, delta in deltas.items():\n",
    "        sign = \"+\" if delta > 0 else \"\"\n",
    "        print(f\"   {feat}: {sign}{delta}\")\n",
    "    \n",
    "    print(f\"\\nüìà Original prediction (Low, Medium, High):\")\n",
    "    print(f\"   {result['base_proba'].round(3)}\")\n",
    "    \n",
    "    print(f\"\\nüìâ Modified prediction (Low, Medium, High):\")\n",
    "    print(f\"   {result['new_proba'].round(3)}\")\n",
    "    \n",
    "    print(f\"\\nüîÑ Probability change:\")\n",
    "    print(f\"   {result['proba_change'].round(3)}\")\n",
    "    \n",
    "    # Interpretazione automatica\n",
    "    print(\"\\nüí° Interpretation:\")\n",
    "    if result['proba_change'][2] < 0:\n",
    "        reduction = abs(result['proba_change'][2] * 100)\n",
    "        print(f\"   ‚úÖ High burnout risk DECREASED by {reduction:.1f}%\")\n",
    "    else:\n",
    "        increase = result['proba_change'][2] * 100\n",
    "        print(f\"   ‚ö†Ô∏è High burnout risk INCREASED by {increase:.1f}%\")\n",
    "    \n",
    "    if result['proba_change'][0] > 0:\n",
    "        improvement = result['proba_change'][0] * 100\n",
    "        print(f\"   ‚úÖ Low burnout probability INCREASED by {improvement:.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No high burnout cases found in test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d79880c",
   "metadata": {},
   "source": [
    "## üìù Conclusioni\n",
    "\n",
    "### Risultati dell'Analisi\n",
    "L'esempio mostra come piccoli cambiamenti comportamentali possano ridurre significativamente il rischio di burnout:\n",
    "- **+1 ora sonno**: migliora recupero fisico e mentale\n",
    "- **-2 ore screen time**: riduce affaticamento visivo e stimolazione digitale\n",
    "- **-1 ora lavoro**: migliora work-life balance\n",
    "\n",
    "### Prossimi Sviluppi\n",
    "1. **UI interattiva**: slider per modificare features in tempo reale\n",
    "2. **Batch analysis**: analizzare intero team per interventi mirati\n",
    "3. **Modello causale**: usare causal inference per validare interventi\n",
    "4. **Integrazione app**: collegare a app wellness per raccomandazioni personalizzate\n",
    "\n",
    "### Limitazioni\n",
    "- Le predizioni sono basate su correlazioni, non causalit√†\n",
    "- Il dataset √® sintetico - validare su dati reali\n",
    "- Gli effetti reali dipendono da molti fattori non modellati"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
