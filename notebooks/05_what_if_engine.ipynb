{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68fec76",
   "metadata": {},
   "source": [
    "# üîÆ What-If Engine - Scenario Analysis\n",
    "\n",
    "## Objective\n",
    "\n",
    "This notebook implements a **\"What-If Engine\"** to explore how behavioral changes affect burnout risk.\n",
    "\n",
    "### Use Case\n",
    "An employee with high burnout risk wants to know:\n",
    "> \"If I sleep 1 extra hour and reduce 2 hours of screen time, will my risk decrease?\"\n",
    "\n",
    "### How It Works\n",
    "1. Take an example from the dataset (e.g., a high burnout case)\n",
    "2. Apply modifications (\"deltas\") to specific features\n",
    "3. Compare predicted probabilities before/after\n",
    "\n",
    "### Practical Applications\n",
    "- **HR Analytics**: identify personalized interventions for at-risk employees\n",
    "- **Self-monitoring**: wellness apps that suggest behavioral changes\n",
    "- **Policy making**: evaluate impact of company policies (e.g., reduced hours)\n",
    "\n",
    "### Limitations\n",
    "- The model predicts **correlations**, not **causation**\n",
    "- Real interventions may have different effects\n",
    "- Synthetic dataset: validate on real data before deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee0f563",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/processed/X_train.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Carica i dati pre-processati come fai in 02/03 (adatta se li salvi su pickle)\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m X_train = \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata/processed/X_train.joblib\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m X_test = load(\u001b[33m\"\u001b[39m\u001b[33mdata/processed/X_test.joblib\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m y_train = load(\u001b[33m\"\u001b[39m\u001b[33mdata/processed/y_train.joblib\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/joblib/numpy_pickle.py:735\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    733\u001b[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[32m    737\u001b[39m             fobj,\n\u001b[32m    738\u001b[39m             validated_mmap_mode,\n\u001b[32m    739\u001b[39m         ):\n\u001b[32m    740\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    741\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    742\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    743\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/processed/X_train.joblib'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SETUP AND MODEL LOADING\n",
    "# =============================================================================\n",
    "# Load trained MLP model for what-if predictions\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path('../data/processed')\n",
    "MODEL_DIR = Path('../models/saved')\n",
    "\n",
    "# =============================================================================\n",
    "# DATA LOADING\n",
    "# =============================================================================\n",
    "# Use same dataset as training for consistent features\n",
    "\n",
    "df = pd.read_parquet(DATA_DIR / 'tabular_ml_ready.parquet')\n",
    "feature_cols = [c for c in df.columns if c not in {'burnout_level', 'burnout_score'}]\n",
    "X = df[feature_cols].values.astype(np.float32)\n",
    "y = df['burnout_level'].values.astype(np.int64)\n",
    "\n",
    "# Split identical to training (same random_state!)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to DataFrame to keep column names\n",
    "X_train = pd.DataFrame(X_train, columns=feature_cols)\n",
    "X_test = pd.DataFrame(X_test, columns=feature_cols)\n",
    "\n",
    "# =============================================================================\n",
    "# MLP MODEL LOADING\n",
    "# =============================================================================\n",
    "# Define same architecture used in training\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Same architecture as 03_deep_learning_mlp.ipynb\"\"\"\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Load saved model\n",
    "model_path = MODEL_DIR / 'mlp_classifier.pt'\n",
    "if model_path.exists():\n",
    "    checkpoint = torch.load(model_path, map_location=DEVICE, weights_only=False)\n",
    "    mlp = MLP(len(feature_cols), 3).to(DEVICE)\n",
    "    mlp.load_state_dict(checkpoint['model_state'])\n",
    "    mlp.eval()  # Inference mode\n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "else:\n",
    "    print(f\"‚ùå Model not found at {model_path}. Run train_mlp.py first.\")\n",
    "\n",
    "# Load scaler (optional, for de-normalizing features)\n",
    "scaler_path = DATA_DIR / 'feature_scaler.joblib'\n",
    "scaler = joblib.load(scaler_path) if scaler_path.exists() else None\n",
    "feature_names = feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef25f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# WHAT-IF FUNCTION\n",
    "# =============================================================================\n",
    "# Main function for scenario analysis\n",
    "\n",
    "def what_if_scenario(model, x_row: pd.Series, deltas: dict, device=DEVICE):\n",
    "    \"\"\"\n",
    "    Analyze how feature modifications change predictions.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained PyTorch model\n",
    "        x_row: A row of features (pd.Series with column names)\n",
    "        deltas: Dict {feature_name: change}\n",
    "                e.g., {\"sleep_hours_mean\": +1.0} = +1 hour of sleep\n",
    "        device: Torch device\n",
    "    \n",
    "    Returns:\n",
    "        dict with:\n",
    "        - x_base: original features\n",
    "        - x_new: modified features\n",
    "        - base_proba: class probabilities (original)\n",
    "        - new_proba: class probabilities (after modification)\n",
    "        - proba_change: difference new - base\n",
    "    \"\"\"\n",
    "    x_base = x_row.copy()\n",
    "    x_new = x_row.copy()\n",
    "    \n",
    "    # Apply modifications\n",
    "    for feat, delta in deltas.items():\n",
    "        if feat in x_new.index:\n",
    "            x_new[feat] = x_new[feat] + delta\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: feature '{feat}' not found in data\")\n",
    "\n",
    "    # Predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Convert to tensors\n",
    "        x_base_tensor = torch.from_numpy(\n",
    "            x_base.values.astype(np.float32)\n",
    "        ).unsqueeze(0).to(device)\n",
    "        x_new_tensor = torch.from_numpy(\n",
    "            x_new.values.astype(np.float32)\n",
    "        ).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        base_logits = model(x_base_tensor)\n",
    "        new_logits = model(x_new_tensor)\n",
    "        \n",
    "        # Convert logits to probabilities\n",
    "        base_proba = torch.softmax(base_logits, dim=1).cpu().numpy()[0]\n",
    "        new_proba = torch.softmax(new_logits, dim=1).cpu().numpy()[0]\n",
    "\n",
    "    return {\n",
    "        \"x_base\": x_base,\n",
    "        \"x_new\": x_new,\n",
    "        \"base_proba\": base_proba,           # [P(low), P(medium), P(high)]\n",
    "        \"new_proba\": new_proba,\n",
    "        \"proba_change\": new_proba - base_proba,  # Difference\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4b76c",
   "metadata": {},
   "source": [
    "## üß™ Example: Intervention Scenario\n",
    "\n",
    "Let's take a **high burnout** case from the test set and simulate an intervention:\n",
    "- +1 hour of sleep (`sleep_hours_mean`)\n",
    "- -2 hours of screen time (`screen_time_hours_mean`)\n",
    "- -1 hour of work (`work_hours_mean`)\n",
    "\n",
    "This simulates a week with better work-life balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f2102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# WHAT-IF ANALYSIS EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "# Find a high burnout case (class 2) for analysis\n",
    "mask_high = (y_test == 2)\n",
    "high_indices = np.where(mask_high)[0]\n",
    "\n",
    "if len(high_indices) > 0:\n",
    "    # Take first high burnout case\n",
    "    idx = high_indices[0]\n",
    "    x_example = X_test.iloc[idx]\n",
    "    \n",
    "    # Define scenario: improve sleep, reduce screen time and work hours\n",
    "    deltas = {\n",
    "        \"sleep_hours_mean\": +1.0,       # +1 hour average sleep\n",
    "        \"screen_time_hours_mean\": -2.0,  # -2 hours average screen time\n",
    "        \"work_hours_mean\": -1.0,         # -1 hour average work\n",
    "    }\n",
    "    \n",
    "    # Execute analysis\n",
    "    result = what_if_scenario(mlp, x_example, deltas)\n",
    "    \n",
    "    # =============================================================================\n",
    "    # RESULTS VISUALIZATION\n",
    "    # =============================================================================\n",
    "    print(\"=\" * 50)\n",
    "    print(\"üîÆ WHAT-IF ANALYSIS RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    print(\"\\nüìä Scenario:\")\n",
    "    for feat, delta in deltas.items():\n",
    "        sign = \"+\" if delta > 0 else \"\"\n",
    "        print(f\"   {feat}: {sign}{delta}\")\n",
    "    \n",
    "    print(f\"\\nüìà Original prediction (Low, Medium, High):\")\n",
    "    print(f\"   {result['base_proba'].round(3)}\")\n",
    "    \n",
    "    print(f\"\\nüìâ Modified prediction (Low, Medium, High):\")\n",
    "    print(f\"   {result['new_proba'].round(3)}\")\n",
    "    \n",
    "    print(f\"\\nüîÑ Probability change:\")\n",
    "    print(f\"   {result['proba_change'].round(3)}\")\n",
    "    \n",
    "    # Automatic interpretation\n",
    "    print(\"\\nüí° Interpretation:\")\n",
    "    if result['proba_change'][2] < 0:\n",
    "        reduction = abs(result['proba_change'][2] * 100)\n",
    "        print(f\"   ‚úÖ High burnout risk DECREASED by {reduction:.1f}%\")\n",
    "    else:\n",
    "        increase = result['proba_change'][2] * 100\n",
    "        print(f\"   ‚ö†Ô∏è High burnout risk INCREASED by {increase:.1f}%\")\n",
    "    \n",
    "    if result['proba_change'][0] > 0:\n",
    "        improvement = result['proba_change'][0] * 100\n",
    "        print(f\"   ‚úÖ Low burnout probability INCREASED by {improvement:.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No high burnout cases found in test set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d79880c",
   "metadata": {},
   "source": [
    "## üìù Conclusions\n",
    "\n",
    "### Analysis Results\n",
    "The example shows how small behavioral changes can significantly reduce burnout risk:\n",
    "- **+1 hour sleep**: improves physical and mental recovery\n",
    "- **-2 hours screen time**: reduces visual fatigue and digital stimulation\n",
    "- **-1 hour work**: improves work-life balance\n",
    "\n",
    "### Future Developments\n",
    "1. **Interactive UI**: sliders to modify features in real-time\n",
    "2. **Batch analysis**: analyze entire team for targeted interventions\n",
    "3. **Causal model**: use causal inference to validate interventions\n",
    "4. **App integration**: connect to wellness app for personalized recommendations\n",
    "\n",
    "### Limitations\n",
    "- Predictions are based on correlations, not causation\n",
    "- Dataset is synthetic - validate on real data\n",
    "- Real effects depend on many unmodeled factors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
