{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "703664d9",
   "metadata": {},
   "source": [
    "# Feature Importance Analysis - Kaggle Notebook\n",
    "\n",
    "## ðŸŽ¯ Objective\n",
    "Analyze which behavioral features are most predictive of mental health outcomes (stress, mood, energy, focus, etc.)\n",
    "\n",
    "## ðŸ“‹ Prerequisites\n",
    "**Before running this notebook:**\n",
    "1. Upload your dataset to Kaggle:\n",
    "   - Go to \"Add Data\" â†’ \"Upload\" â†’ Select `daily_logs.csv` and `weekly_summaries.csv`\n",
    "   - OR use an existing Kaggle dataset\n",
    "2. Update the `KAGGLE_INPUT_PATH` variable in the next cell to match your dataset location\n",
    "\n",
    "## ðŸ”„ What This Notebook Does\n",
    "1. âœ… Fixes file path issues automatically\n",
    "2. âœ… Creates burnout labels from raw data\n",
    "3. âœ… Runs 3 feature importance methods (Random Forest, Permutation, Correlation)\n",
    "4. âœ… Generates visualizations for all mental health targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3367746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP - UPDATE THIS PATH TO YOUR KAGGLE DATASET!\n",
    "# ============================================================================\n",
    "\n",
    "# ðŸ”§ CHANGE THIS to match your Kaggle dataset path\n",
    "# Example: '/kaggle/input/mental-health-daily-logs/'\n",
    "# Example: '/kaggle/input/burnout-prediction-dataset/'\n",
    "KAGGLE_INPUT_PATH = '/kaggle/input/your-dataset-name-here/'\n",
    "\n",
    "# Check if path exists\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CHECKING KAGGLE ENVIRONMENT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if Path(KAGGLE_INPUT_PATH).exists():\n",
    "    print(f\"âœ“ Dataset found: {KAGGLE_INPUT_PATH}\")\n",
    "    print(f\"âœ“ Available files:\")\n",
    "    for f in os.listdir(KAGGLE_INPUT_PATH):\n",
    "        print(f\"  - {f}\")\n",
    "else:\n",
    "    print(f\"âŒ Dataset not found: {KAGGLE_INPUT_PATH}\")\n",
    "    print(f\"\\nðŸ“ Available datasets in /kaggle/input/:\")\n",
    "    if Path('/kaggle/input').exists():\n",
    "        for d in os.listdir('/kaggle/input/'):\n",
    "            print(f\"  - {d}\")\n",
    "    print(\"\\nâš ï¸  UPDATE KAGGLE_INPUT_PATH variable above with the correct path!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7bd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: Clone Repository & Setup\n",
    "# ============================================================================\n",
    "\n",
    "!git clone https://github.com/danpinocontrollino/FDS-Project.git\n",
    "%cd FDS-Project\n",
    "\n",
    "# Create directory structure\n",
    "!mkdir -p data/raw data/processed\n",
    "\n",
    "# Copy raw data from Kaggle input to expected location\n",
    "import shutil\n",
    "\n",
    "# Update these filenames if your files have different names\n",
    "daily_logs_file = 'daily_logs.csv'  # or 'daily_all.csv' or 'daily.csv'\n",
    "weekly_summary_file = 'weekly_summaries.csv'  # or 'weekly.csv'\n",
    "\n",
    "# Try to copy files\n",
    "try:\n",
    "    src = f'{KAGGLE_INPUT_PATH}/{daily_logs_file}'\n",
    "    dst = 'data/raw/daily_logs.csv'\n",
    "    shutil.copy(src, dst)\n",
    "    print(f\"âœ“ Copied {daily_logs_file} â†’ {dst}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error copying {daily_logs_file}: {e}\")\n",
    "    print(f\"   Available files: {os.listdir(KAGGLE_INPUT_PATH)}\")\n",
    "\n",
    "try:\n",
    "    src = f'{KAGGLE_INPUT_PATH}/{weekly_summary_file}'\n",
    "    dst = 'data/raw/weekly_summaries.csv'\n",
    "    shutil.copy(src, dst)\n",
    "    print(f\"âœ“ Copied {weekly_summary_file} â†’ {dst}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error copying {weekly_summary_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75daf9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: Create Burnout Labels\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATING BURNOUT LABELS FROM RAW DATA\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "!python scripts/create_burnout_labels.py\n",
    "\n",
    "# Verify output\n",
    "if Path('data/processed/daily_with_burnout.parquet').exists():\n",
    "    print(\"\\nâœ“ Successfully created daily_with_burnout.parquet\")\n",
    "else:\n",
    "    print(\"\\nâŒ Failed to create processed data files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b2bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Load & Inspect Data\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load preprocessed data\n",
    "df = pd.read_parquet('data/processed/daily_with_burnout.parquet')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA LOADED SUCCESSFULLY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"âœ“ Shape: {df.shape[0]:,} rows Ã— {df.shape[1]} columns\")\n",
    "print(f\"âœ“ Memory: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "print(f\"\\nðŸ“Š First few rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(f\"\\nðŸ“‹ Available columns:\")\n",
    "for col in df.columns:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea30d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Feature columns (17 behavioral features)\n",
    "FEATURE_COLS = [\n",
    "    \"sleep_hours\", \"sleep_quality\", \"work_hours\", \"meetings_count\",\n",
    "    \"tasks_completed\", \"emails_received\", \"commute_minutes\",\n",
    "    \"exercise_minutes\", \"steps_count\", \"caffeine_mg\", \"alcohol_units\",\n",
    "    \"screen_time_hours\", \"social_interactions\", \"outdoor_time_minutes\",\n",
    "    \"diet_quality\", \"work_pressure\", \"weather_mood_impact\",\n",
    "]\n",
    "\n",
    "# Target columns - check which are available in your data\n",
    "TARGET_COLS = [\n",
    "    \"stress_level\", \"mood_score\", \"energy_level\", \"focus_score\",\n",
    "    \"perceived_stress_scale\", \"anxiety_score\", \"depression_score\",\n",
    "    \"job_satisfaction\", \"burnout_score\"\n",
    "]\n",
    "\n",
    "# Filter to only available targets\n",
    "TARGET_COLS = [t for t in TARGET_COLS if t in df.columns]\n",
    "print(f\"âœ“ Will analyze {len(TARGET_COLS)} targets: {TARGET_COLS}\")\n",
    "\n",
    "FEATURE_NAMES = {\n",
    "    \"sleep_hours\": \"Sleep Hours\", \"sleep_quality\": \"Sleep Quality\",\n",
    "    \"work_hours\": \"Work Hours\", \"meetings_count\": \"Meetings\",\n",
    "    \"tasks_completed\": \"Tasks\", \"emails_received\": \"Emails\",\n",
    "    \"commute_minutes\": \"Commute\", \"exercise_minutes\": \"Exercise\",\n",
    "    \"steps_count\": \"Steps\", \"caffeine_mg\": \"Caffeine\",\n",
    "    \"alcohol_units\": \"Alcohol\", \"screen_time_hours\": \"Screen Time\",\n",
    "    \"social_interactions\": \"Social\", \"outdoor_time_minutes\": \"Outdoor Time\",\n",
    "    \"diet_quality\": \"Diet\", \"work_pressure\": \"Work Pressure\",\n",
    "    \"weather_mood_impact\": \"Weather Impact\",\n",
    "}\n",
    "\n",
    "# Sample for faster analysis\n",
    "SAMPLE_SIZE = 50000\n",
    "if len(df) > SAMPLE_SIZE:\n",
    "    print(f\"ðŸ“‰ Sampling {SAMPLE_SIZE:,} rows for faster analysis...\")\n",
    "    df = df.sample(n=SAMPLE_SIZE, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1dff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def prepare_data(df, target):\n",
    "    \"\"\"Prepare features and target for analysis.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PREPARING DATA FOR: {target.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    available_features = [f for f in FEATURE_COLS if f in df.columns]\n",
    "    print(f\"âœ“ Found {len(available_features)}/{len(FEATURE_COLS)} features\")\n",
    "    \n",
    "    if target not in df.columns:\n",
    "        print(f\"âŒ Target '{target}' not found\")\n",
    "        return None, None, None\n",
    "    \n",
    "    df_clean = df[available_features + [target]].copy().dropna(subset=[target])\n",
    "    \n",
    "    # Handle categorical features\n",
    "    if 'work_pressure' in df_clean.columns:\n",
    "        pressure_map = {'low': 0, 'medium': 1, 'high': 2}\n",
    "        df_clean['work_pressure'] = df_clean['work_pressure'].map(pressure_map)\n",
    "    \n",
    "    # Fill missing\n",
    "    for col in available_features:\n",
    "        if df_clean[col].isna().any():\n",
    "            df_clean[col].fillna(df_clean[col].mean(), inplace=True)\n",
    "    \n",
    "    X = df_clean[available_features].values\n",
    "    y = df_clean[target].values\n",
    "    \n",
    "    print(f\"âœ“ Dataset: {len(X):,} samples Ã— {len(available_features)} features\")\n",
    "    print(f\"âœ“ Target: mean={y.mean():.2f}, std={y.std():.2f}\")\n",
    "    \n",
    "    return X, y, available_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664d45dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_importance(X, y, feature_names):\n",
    "    \"\"\"Calculate feature importance using Random Forest.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"METHOD 1: RANDOM FOREST FEATURE IMPORTANCE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    train_score = rf.score(X_train, y_train)\n",
    "    test_score = rf.score(X_test, y_test)\n",
    "    print(f\"âœ“ RÂ² Score - Train: {train_score:.3f}, Test: {test_score:.3f}\")\n",
    "    \n",
    "    importances = rf.feature_importances_\n",
    "    df_importance = pd.DataFrame({\n",
    "        'Feature': [FEATURE_NAMES.get(f, f) for f in feature_names],\n",
    "        'Importance': importances,\n",
    "        'Importance_pct': importances * 100\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nðŸ† Top 10 Features:\")\n",
    "    for idx, row in df_importance.head(10).iterrows():\n",
    "        print(f\"  {idx+1}. {row['Feature']}: {row['Importance_pct']:.2f}%\")\n",
    "    \n",
    "    return df_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997913d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_importance_analysis(X, y, feature_names):\n",
    "    \"\"\"Calculate permutation importance.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"METHOD 2: PERMUTATION IMPORTANCE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    perm_imp = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "    \n",
    "    df_importance = pd.DataFrame({\n",
    "        'Feature': [FEATURE_NAMES.get(f, f) for f in feature_names],\n",
    "        'Importance': perm_imp.importances_mean,\n",
    "        'Std': perm_imp.importances_std\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nðŸ† Top 10 Features:\")\n",
    "    for idx, row in df_importance.head(10).iterrows():\n",
    "        print(f\"  {idx+1}. {row['Feature']}: {row['Importance']:.4f} Â± {row['Std']:.4f}\")\n",
    "    \n",
    "    return df_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_analysis(df, target, feature_cols):\n",
    "    \"\"\"Calculate correlations with target.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"METHOD 3: CORRELATION ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    correlations = []\n",
    "    for feature in feature_cols:\n",
    "        if feature in df.columns:\n",
    "            corr = df[feature].corr(df[target])\n",
    "            correlations.append({\n",
    "                'Feature': FEATURE_NAMES.get(feature, feature),\n",
    "                'Correlation': corr,\n",
    "                'Abs_Correlation': abs(corr),\n",
    "                'Direction': 'â†‘ Positive' if corr > 0 else 'â†“ Negative'\n",
    "            })\n",
    "    \n",
    "    df_corr = pd.DataFrame(correlations).sort_values('Abs_Correlation', ascending=False)\n",
    "    \n",
    "    print(\"\\nðŸ† Top 10 Correlations:\")\n",
    "    for idx, row in df_corr.head(10).iterrows():\n",
    "        print(f\"  {idx+1}. {row['Feature']} {row['Direction']}: r={row['Correlation']:.3f}\")\n",
    "    \n",
    "    return df_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a517350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(df_importance, target, method):\n",
    "    \"\"\"Plot feature importance bar chart.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    df_plot = df_importance.head(15).copy()\n",
    "    \n",
    "    if 'Importance' in df_plot.columns:\n",
    "        df_plot = df_plot.sort_values('Importance')\n",
    "        y_col = 'Importance'\n",
    "    else:\n",
    "        df_plot = df_plot.sort_values('Abs_Correlation')\n",
    "        y_col = 'Abs_Correlation'\n",
    "    \n",
    "    colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(df_plot)))\n",
    "    plt.barh(df_plot['Feature'], df_plot[y_col], color=colors)\n",
    "    \n",
    "    plt.xlabel('Importance', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Feature', fontsize=12, fontweight='bold')\n",
    "    plt.title(f'Feature Importance: {target.replace(\"_\", \" \").title()}\\n({method})',\n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_comparison(results, target):\n",
    "    \"\"\"Compare all 3 methods side by side.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    for idx, (method, df_result) in enumerate(results.items()):\n",
    "        ax = axes[idx]\n",
    "        df_plot = df_result.head(10).copy()\n",
    "        \n",
    "        y_col = 'Importance' if 'Importance' in df_plot.columns else 'Abs_Correlation'\n",
    "        df_plot = df_plot.sort_values(y_col)\n",
    "        \n",
    "        colors = plt.cm.plasma(np.linspace(0.3, 0.9, len(df_plot)))\n",
    "        ax.barh(df_plot['Feature'], df_plot[y_col], color=colors)\n",
    "        ax.set_xlabel('Importance', fontweight='bold')\n",
    "        ax.set_title(method, fontsize=12, fontweight='bold')\n",
    "        ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    fig.suptitle(f'Method Comparison: {target.replace(\"_\", \" \").title()}',\n",
    "                 fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_target(df, target):\n",
    "    \"\"\"Run complete analysis for one target.\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ANALYZING: {target.replace('_', ' ').upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    X, y, feature_names = prepare_data(df, target)\n",
    "    if X is None:\n",
    "        return None\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Method 1: Random Forest\n",
    "    df_rf = random_forest_importance(X, y, feature_names)\n",
    "    results['Random Forest'] = df_rf\n",
    "    plot_feature_importance(df_rf, target, 'Random Forest')\n",
    "    \n",
    "    # Method 2: Permutation\n",
    "    df_perm = permutation_importance_analysis(X, y, feature_names)\n",
    "    results['Permutation'] = df_perm\n",
    "    plot_feature_importance(df_perm, target, 'Permutation Importance')\n",
    "    \n",
    "    # Method 3: Correlation\n",
    "    df_clean = df[[f for f in FEATURE_COLS if f in df.columns] + [target]].dropna(subset=[target])\n",
    "    if 'work_pressure' in df_clean.columns:\n",
    "        df_clean['work_pressure'] = df_clean['work_pressure'].map({'low': 0, 'medium': 1, 'high': 2})\n",
    "    df_corr = correlation_analysis(df_clean, target, feature_names)\n",
    "    results['Correlation'] = df_corr\n",
    "    \n",
    "    # Comparison plot\n",
    "    plot_comparison(results, target)\n",
    "    \n",
    "    # Consensus ranking\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CONSENSUS RANKING\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    all_features = set()\n",
    "    for method_df in results.values():\n",
    "        all_features.update(method_df['Feature'].tolist())\n",
    "    \n",
    "    consensus = []\n",
    "    for feature in all_features:\n",
    "        ranks = []\n",
    "        for method_df in results.values():\n",
    "            if feature in method_df['Feature'].values:\n",
    "                rank = method_df[method_df['Feature'] == feature].index[0] + 1\n",
    "            else:\n",
    "                rank = 999\n",
    "            ranks.append(rank)\n",
    "        consensus.append({'Feature': feature, 'Avg_Rank': np.mean(ranks)})\n",
    "    \n",
    "    df_consensus = pd.DataFrame(consensus).sort_values('Avg_Rank')\n",
    "    \n",
    "    print(\"\\nðŸ† TOP 10 FEATURES (consensus across all methods):\")\n",
    "    for idx, row in df_consensus.head(10).iterrows():\n",
    "        print(f\"  {idx+1}. {row['Feature']} (Avg Rank: {row['Avg_Rank']:.1f})\")\n",
    "    \n",
    "    return results, df_consensus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4853cc3f",
   "metadata": {},
   "source": [
    "## ðŸš€ Run Analysis for All Targets\n",
    "\n",
    "This will analyze each mental health outcome (stress, mood, energy, etc.) and show which behavioral features are most predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aa4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis for all targets\n",
    "all_results = {}\n",
    "all_consensus = {}\n",
    "\n",
    "for target in TARGET_COLS:\n",
    "    if target in df.columns:\n",
    "        results, consensus = analyze_target(df, target)\n",
    "        all_results[target] = results\n",
    "        all_consensus[target] = consensus\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸  Skipping {target} - not in dataset\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"âœ“ Analyzed {len(all_results)} targets\")\n",
    "print(f\"âœ“ Generated {len(all_results) * 4} visualizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e48e35e",
   "metadata": {},
   "source": [
    "## ðŸ“Š Summary: Top Predictive Features Across All Targets\n",
    "\n",
    "View the consensus features that matter most for mental health outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7218e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary DataFrame\n",
    "summary_data = []\n",
    "for target, consensus_df in all_consensus.items():\n",
    "    top_5 = consensus_df.head(5)\n",
    "    for idx, row in top_5.iterrows():\n",
    "        summary_data.append({\n",
    "            'Target': target.replace('_', ' ').title(),\n",
    "            'Rank': idx + 1,\n",
    "            'Feature': row['Feature'],\n",
    "            'Avg_Rank': row['Avg_Rank']\n",
    "        })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "\n",
    "# Pivot to show top features per target\n",
    "pivot = df_summary.pivot_table(\n",
    "    index='Feature',\n",
    "    columns='Target',\n",
    "    values='Rank',\n",
    "    aggfunc='first'\n",
    ").fillna('-')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TOP 5 FEATURES PER TARGET\")\n",
    "print(\"=\"*80)\n",
    "display(pivot)\n",
    "\n",
    "# Find universal predictors (top 5 for multiple targets)\n",
    "feature_counts = df_summary['Feature'].value_counts()\n",
    "universal = feature_counts[feature_counts >= 3]\n",
    "\n",
    "if len(universal) > 0:\n",
    "    print(\"\\nðŸŒŸ UNIVERSAL PREDICTORS (important for 3+ targets):\")\n",
    "    for feature, count in universal.items():\n",
    "        print(f\"  â€¢ {feature}: Important for {count} targets\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
