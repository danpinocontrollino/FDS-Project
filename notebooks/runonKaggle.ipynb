{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ced6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# KAGGLE GPU DRIVER NOTEBOOK - Burnout Prediction Training Pipeline\n",
    "# ============================================================================\n",
    "# This notebook runs the full training pipeline on Kaggle's GPU environment\n",
    "# Dataset: Work-Life Balance Synthetic Daily Wellness Dataset\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215fb02",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "Clone the repository and install dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5369c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fds-project'...\n",
      "remote: Enumerating objects: 214, done.\u001b[K\n",
      "remote: Counting objects: 100% (214/214), done.\u001b[K\n",
      "remote: Enumerating objects: 214, done.\u001b[K\u001b[K\n",
      "remote: Counting objects: 100% (214/214), done.\u001b[K\n",
      "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
      "remote: Compressing objects: 100% (143/143), done.\u001b[K\n",
      "remote: Total 214 (delta 82), reused 161 (delta 50), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (214/214), 8.82 MiB | 22.68 MiB/s, done.\n",
      "remote: Total 214 (delta 82), reused 161 (delta 50), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (214/214), 8.82 MiB | 22.68 MiB/s, done.\n",
      "Resolving deltas: 100% (82/82), done.\n",
      "Resolving deltas: 100% (82/82), done.\n",
      "/workspaces/FDS-Project/notebooks/fds-project\n",
      "/workspaces/FDS-Project/notebooks/fds-project\n"
     ]
    }
   ],
   "source": [
    "# Clone the GitHub repository (if not already cloned)\n",
    "import os\n",
    "if not os.path.exists('/kaggle/working/fds-project'):\n",
    "    !git clone https://github.com/danpinocontrollino/fds-project.git /kaggle/working/fds-project\n",
    "\n",
    "# Change working directory to the cloned repo (MUST run before any scripts)\n",
    "%cd /kaggle/working/fds-project\n",
    "\n",
    "# Verify we're in the right place\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Install required libraries (not pre-installed on Kaggle)\n",
    "!pip install -q joblib pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c5d3e4",
   "metadata": {},
   "source": [
    "## Step 2: Data Setup\n",
    "Copy the Kaggle dataset into the expected `data/raw/` directory.\n",
    "\n",
    "**Important:** Kaggle input paths are read-only, so we must copy (not symlink) the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e08b2f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying dataset files from Kaggle input...\n",
      "\n",
      "Files in data/raw:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Kaggle's input path for the dataset\n",
    "KAGGLE_INPUT = Path(\"/kaggle/input/worklife-balance-synthetic-daily-wellness-dataset\")\n",
    "\n",
    "# Target directory in the cloned repo\n",
    "RAW_DIR = Path(\"data/raw\")\n",
    "RAW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Copy all CSV files from Kaggle input to data/raw/\n",
    "print(\"Copying dataset files from Kaggle input...\")\n",
    "for csv_file in KAGGLE_INPUT.glob(\"*.csv\"):\n",
    "    dest = RAW_DIR / csv_file.name\n",
    "    shutil.copy(csv_file, dest)\n",
    "    print(f\"  ✓ {csv_file.name} -> {dest}\")\n",
    "\n",
    "# Verify the files were copied\n",
    "print(f\"\\nFiles in {RAW_DIR}:\")\n",
    "for f in RAW_DIR.iterdir():\n",
    "    print(f\"  - {f.name} ({f.stat().st_size / 1024:.1f} KB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74324afb",
   "metadata": {},
   "source": [
    "## Step 3: Pipeline Execution\n",
    "Run the preprocessing scripts to generate burnout labels and prepare features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48516830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Running: create_burnout_labels.py\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/FDS-Project/notebooks/fds-project/scripts/create_burnout_labels.py\", line 209, in <module>\n",
      "    main()\n",
      "  File \"/workspaces/FDS-Project/notebooks/fds-project/scripts/create_burnout_labels.py\", line 187, in main\n",
      "    weekly, daily = load_raw_frames()\n",
      "                    ^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/FDS-Project/notebooks/fds-project/scripts/create_burnout_labels.py\", line 68, in load_raw_frames\n",
      "    weekly = pd.read_csv(RAW_DIR / \"weekly_summaries.csv\", parse_dates=[\"week_start\"])\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/FDS-Project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1026, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/FDS-Project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 620, in _read\n",
      "    parser = TextFileReader(filepath_or_buffer, **kwds)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/FDS-Project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1620, in __init__\n",
      "    self._engine = self._make_engine(f, self.engine)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/workspaces/FDS-Project/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py\", line 1880, in _make_engine\n",
      "    self.handles = get_handle(\n",
      "                   ^^^^^^^^^^^\n",
      "  File \"/workspaces/FDS-Project/.venv/lib/python3.12/site-packages/pandas/io/common.py\", line 873, in get_handle\n",
      "    handle = open(\n",
      "             ^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/raw/weekly_summaries.csv'\n",
      "    handle = open(\n",
      "             ^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'data/raw/weekly_summaries.csv'\n"
     ]
    }
   ],
   "source": [
    "# Step 3a: Generate burnout labels from raw data\n",
    "print(\"=\" * 60)\n",
    "print(\"Running: create_burnout_labels.py\")\n",
    "print(\"=\" * 60)\n",
    "!python scripts/create_burnout_labels.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408bc967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Running: preprocess.py\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/workspaces/FDS-Project/notebooks/fds-project/scripts/preprocess.py\", line 364, in <module>\n",
      "    main()\n",
      "  File \"/workspaces/FDS-Project/notebooks/fds-project/scripts/preprocess.py\", line 348, in main\n",
      "    ensure_inputs_exist()\n",
      "  File \"/workspaces/FDS-Project/notebooks/fds-project/scripts/preprocess.py\", line 123, in ensure_inputs_exist\n",
      "    raise FileNotFoundError(\n",
      "FileNotFoundError: Missing processed parquet files. Run scripts/create_burnout_labels.py first: data/processed/daily_with_burnout.parquet, data/processed/weekly_with_burnout.parquet\n"
     ]
    }
   ],
   "source": [
    "# Step 3b: Preprocess features for MLP model\n",
    "print(\"=\" * 60)\n",
    "print(\"Running: preprocess.py\")\n",
    "print(\"=\" * 60)\n",
    "!python scripts/preprocess.py\n",
    "\n",
    "# Create models directory for saving (ensure it exists before training)\n",
    "from pathlib import Path\n",
    "Path(\"models/saved\").mkdir(parents=True, exist_ok=True)\n",
    "print(f\"\\n✓ Created models/saved directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75644c8c",
   "metadata": {},
   "source": [
    "## Step 4: Model Training (Forecasting Mode)\n",
    "Train all models using GPU acceleration.\n",
    "\n",
    "**IMPORTANT: All sequence models now predict NEXT WEEK's burnout (7 days ahead).**\n",
    "This prevents data leakage and enables realistic early warning.\n",
    "\n",
    "**Models:**\n",
    "- MLP (Multi-Layer Perceptron) - tabular baseline (same-week, for comparison)\n",
    "- LSTM (Long Short-Term Memory) - forecasting 7 days ahead\n",
    "- GRU (Gated Recurrent Unit) - forecasting 7 days ahead\n",
    "- Transformer - forecasting 7 days ahead\n",
    "\n",
    "**Configuration:**\n",
    "- Window: 7 days (weekly patterns)\n",
    "- Forecast Horizon: 7 days (predict next week's burnout)\n",
    "- Epochs: 40\n",
    "- Sample Users: 100% (use full dataset with GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14df20cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MLP model (tabular baseline)\n",
    "%cd /kaggle/working/fds-project\n",
    "print(\"=\" * 60)\n",
    "print(\"Training: MLP Classifier (Tabular)\")\n",
    "print(\"=\" * 60)\n",
    "!python scripts/train_mlp.py --epochs 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b2f666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Training: Transformer Sequence Model\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: train_lstm.py [-h] [--model {lstm,gru,cnn}] [--window WINDOW]\n",
      "                     [--epochs EPOCHS] [--batch-size BATCH_SIZE] [--lr LR]\n",
      "                     [--sample-users SAMPLE_USERS]\n",
      "train_lstm.py: error: argument --model: invalid choice: 'transformer' (choose from lstm, gru, cnn)\n"
     ]
    }
   ],
   "source": [
    "# Train LSTM model for Burnout (forecasting 7 days ahead)\n",
    "%cd /kaggle/working/fds-project\n",
    "print(\"=\" * 60)\n",
    "print(\"Training: LSTM Burnout Predictor (7 Days Ahead)\")\n",
    "print(\"=\" * 60)\n",
    "!python scripts/train_lstm.py --model lstm --target burnout --window 7 --epochs 40 --sample-users 1.0 --forecast-horizon 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da638049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GRU model for Burnout (forecasting 7 days ahead)\n",
    "%cd /kaggle/working/fds-project\n",
    "print(\"=\" * 60)\n",
    "print(\"Training: GRU Burnout Predictor (7 Days Ahead)\")\n",
    "print(\"=\" * 60)\n",
    "!python scripts/train_lstm.py --model gru --target burnout --window 7 --epochs 40 --sample-users 1.0 --forecast-horizon 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dfbe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Transformer model for Burnout (forecasting 7 days ahead)\n",
    "%cd /kaggle/working/fds-project\n",
    "print(\"=\" * 60)\n",
    "print(\"Training: Transformer Burnout Predictor (7 Days Ahead)\")\n",
    "print(\"=\" * 60)\n",
    "!python scripts/train_transformer.py --target burnout --window 7 --epochs 40 --sample-users 1.0 --forecast-horizon 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc4e86f",
   "metadata": {},
   "source": [
    "## Step 5: MAE Pre-training & Fine-tuning\n",
    "Train a Masked Autoencoder (self-supervised) then fine-tune for classification.\n",
    "\n",
    "**MAE learns behavioral patterns by reconstructing masked days.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51083298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5a: MAE Pre-training (self-supervised)\n",
    "%cd /kaggle/working/fds-project\n",
    "print(\"=\" * 60)\n",
    "print(\"MAE Pre-training: Learning behavioral patterns\")\n",
    "print(\"=\" * 60)\n",
    "!python scripts/train_mae.py --epochs 50 --sample-users 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3ba0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5b: Fine-tune MAE for classification (forecasting mode)\n",
    "%cd /kaggle/working/fds-project\n",
    "print(\"=\" * 60)\n",
    "print(\"MAE Fine-tuning: Transfer learning for burnout classification\")\n",
    "print(\"=\" * 60)\n",
    "!python scripts/train_mae_classifier.py --epochs 30 --sample-users 1.0 --forecast-horizon 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cde3c2",
   "metadata": {},
   "source": [
    "## Step 6: CVAE Smart Advisor\n",
    "Train a Conditional VAE that can suggest lifestyle changes to reduce burnout.\n",
    "\n",
    "**Generates \"counterfactual\" schedules: \"What would your week look like with low burnout?\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b84c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train CVAE Smart Advisor\n",
    "%cd /kaggle/working/fds-project\n",
    "print(\"=\" * 60)\n",
    "print(\"Training: CVAE Smart Advisor (Generative Model)\")\n",
    "print(\"=\" * 60)\n",
    "!python scripts/train_cvae.py --epochs 100 --sample-users 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f01b7a",
   "metadata": {},
   "source": [
    "## Step 7: Focus/Deep Work Prediction\n",
    "Train models to predict tomorrow's focus level based on the last 7 days.\n",
    "\n",
    "**Focus prediction has stronger correlates than burnout:**\n",
    "- meetings_count: -0.31 correlation (fewer meetings = better focus)\n",
    "- stress_level: -0.20 correlation\n",
    "- sleep_hours: +0.16 correlation\n",
    "\n",
    "**Target: focus_level (Low/Medium/High based on focus_score 1-10)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f17c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LSTM for Focus prediction (next day)\n",
    "%cd /kaggle/working/fds-project\n",
    "print(\"=\" * 60)\n",
    "print(\"Training: LSTM Focus Predictor (Next Day)\")\n",
    "print(\"=\" * 60)\n",
    "!python scripts/train_lstm.py --model lstm --target focus --window 7 --epochs 40 --sample-users 1.0 --forecast-horizon 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17997e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Transformer for Focus prediction (next day)\n",
    "%cd /kaggle/working/fds-project\n",
    "print(\"=\" * 60)\n",
    "print(\"Training: Transformer Focus Predictor (Next Day)\")\n",
    "print(\"=\" * 60)\n",
    "!python scripts/train_transformer.py --target focus --window 7 --epochs 40 --sample-users 1.0 --forecast-horizon 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea9cdf8",
   "metadata": {},
   "source": [
    "## Step 7: Save Models to Kaggle Output\n",
    "Copy all trained models to `/kaggle/working/` so they persist after the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba555ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/kaggle'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/pathlib.py:1311\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/kaggle/working/models'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/pathlib.py:1311\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/kaggle/working'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m MODEL_DIR = Path(\u001b[33m\"\u001b[39m\u001b[33mmodels/saved\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m OUTPUT_DIR = Path(\u001b[33m\"\u001b[39m\u001b[33m/kaggle/working/models\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mOUTPUT_DIR\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSaving trained models to Kaggle output...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model_file \u001b[38;5;129;01min\u001b[39;00m MODEL_DIR.glob(\u001b[33m\"\u001b[39m\u001b[33m*.pt\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/pathlib.py:1315\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent == \u001b[38;5;28mself\u001b[39m:\n\u001b[32m   1314\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1315\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28mself\u001b[39m.mkdir(mode, parents=\u001b[38;5;28;01mFalse\u001b[39;00m, exist_ok=exist_ok)\n\u001b[32m   1317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1318\u001b[39m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[32m   1319\u001b[39m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/pathlib.py:1315\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent == \u001b[38;5;28mself\u001b[39m:\n\u001b[32m   1314\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1315\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1316\u001b[39m     \u001b[38;5;28mself\u001b[39m.mkdir(mode, parents=\u001b[38;5;28;01mFalse\u001b[39;00m, exist_ok=exist_ok)\n\u001b[32m   1317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[32m   1318\u001b[39m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[32m   1319\u001b[39m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/pathlib.py:1311\u001b[39m, in \u001b[36mPath.mkdir\u001b[39m\u001b[34m(self, mode, parents, exist_ok)\u001b[39m\n\u001b[32m   1307\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1308\u001b[39m \u001b[33;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[32m   1309\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1311\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[32m   1313\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parent == \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: '/kaggle'"
     ]
    }
   ],
   "source": [
    "# Copy trained models to Kaggle's output directory\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Use absolute path - the repo is cloned to /kaggle/working/fds-project\n",
    "REPO_DIR = Path(\"/kaggle/working/fds-project\")\n",
    "MODEL_DIR = REPO_DIR / \"models\" / \"saved\"\n",
    "\n",
    "print(f\"Looking for models in: {MODEL_DIR}\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "# Create the output directory\n",
    "OUTPUT_DIR = Path(\"/kaggle/working\")\n",
    "\n",
    "# Check if models exist\n",
    "if MODEL_DIR.exists():\n",
    "    model_files = list(MODEL_DIR.glob(\"*.pt\"))\n",
    "    if model_files:\n",
    "        print(f\"\\nFound {len(model_files)} model files:\")\n",
    "        for model_file in model_files:\n",
    "            dest = OUTPUT_DIR / model_file.name\n",
    "            shutil.copy(model_file, dest)\n",
    "            print(f\"  ✓ Copied: {model_file.name} -> {dest}\")\n",
    "        print(f\"\\n✅ Models saved! Download from Kaggle's 'Output' tab.\")\n",
    "    else:\n",
    "        print(\"❌ No .pt files found in models/saved/\")\n",
    "        print(\"   The training scripts may not have saved properly.\")\n",
    "else:\n",
    "    print(f\"❌ Directory does not exist: {MODEL_DIR}\")\n",
    "    print(\"\\nSearching for .pt files anywhere in working directory...\")\n",
    "    !find /kaggle/working -name \"*.pt\" -type f 2>/dev/null\n",
    "    \n",
    "    print(\"\\nDirectory structure:\")\n",
    "    !ls -la /kaggle/working/fds-project/models/ 2>/dev/null || echo \"models/ dir not found\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
